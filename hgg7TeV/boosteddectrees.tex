\subsection{Boosted Decision Trees}
\label{sec:bdts}

BDTs are used frequently in the $\Hgg$ search described in this
chapter in order to acheive the maximum sensitivity to a potential signal.
For most of the BDTs used in this analysis, the desired effect
of the BDT is to provide separation between signal and background processes. 
The first step in producing a BDT of this tyoe is to identify a list of ``input'' 
variables which describe the event objects and provide discrimination 
between signal and background.  
These can be variables such as the $\rnine$ and $\sigieie$ 
of the photon superclusters or kinematic variables of the event such as
the transverse momentum of the diphoton system ($\ptgg$). 
Additional variables such as the positions of the photons within the detector,
are often used so that the BDT can account for correlations between the 
input variables due to detector effects.

A decision tree (DT) is then trained on a MC simulation sample of signal and background 
events. The DT splits the events into two sub-samples by applying a series of cuts
on the input variables. The purity, $p$, of each sub-sample is defined as 
the fraction of the events which are signal, 
\begin{equation}
p = \frac{N_{s}}{N_{s}+N_{b}}.
\end{equation}
A separation criterion is defined to decide whether or not to further sub-divide
that subset. A number of criterion definitions exist, though commonly the 
Gini index, $p(1-p)$ is used. Values which are close to one indicate 
the sample is polluted by background, so above some configurable threshold, 
the sub-sample is further split and the process continues. 
This continues until either all sub-samples are below the threshold or the
user-defined maximum number of splitting levels (tree depth) is reached. 
Each MC event is then assigned a value of -1 or +1 depending on whether it is
or is not in a sub-sample with $p>0.5$. 
 
